{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains all classes used in the project, as well as an example of a complete execution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Given a training dataset, fit a classifier, then fit a regressor for every class.\n",
    "* Given the testing dataset, classify sample then perform regression using the appropriate regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn import metrics\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"user_verified\", \"user_statuses_count\", \"user_followers_count\", \"user_friends_count\",\"polarity\",\"subjectivity\", \"num_hashtags\", \"num_mentions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction():\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def transform(self):\n",
    "        df = self.df\n",
    "        #sentiment\n",
    "        sentiment = pd.Series(df['text']).apply(lambda x: TextBlob(x).sentiment)\n",
    "        polarity = sentiment.apply(lambda x: x[0])\n",
    "        subjectivity = sentiment.apply(lambda x: x[1])\n",
    "        df['polarity']=polarity\n",
    "        df['subjectivity']=subjectivity\n",
    "\n",
    "        #verified\n",
    "        df[\"user_verified\"]=df[\"user_verified\"].astype(int)\n",
    "\n",
    "        #hashtags\n",
    "        df[\"hashtags\"].replace(np.nan, \"\", inplace = True)\n",
    "        df[\"num_hashtags\"]=df[\"hashtags\"].apply(lambda x : len(x.split(\", \")) if x!= \"\" else 0)\n",
    "        df['text']=df['text'].apply(lambda x: x.replace('\\r',''))\n",
    "\n",
    "        #length\n",
    "        df[\"length\"]=df[\"text\"].apply(lambda x : len(TextBlob(x).split(\" \")))\n",
    "        \n",
    "        #num_mentions\n",
    "        df[\"user_mentions\"].replace(np.nan, \"\", inplace = True)\n",
    "        df[\"num_mentions\"]=df[\"user_mentions\"].apply(lambda x : len(x.split(\", \")) if x!= \"\" else 0)\n",
    "\n",
    "        #fillna\n",
    "        df.fillna(0,inplace = True)\n",
    "        \n",
    "        self.transformed_df = df\n",
    "        \n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification():\n",
    "    \n",
    "    def label(count):\n",
    "        if count == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            if count<=10:\n",
    "                return 1\n",
    "            else:\n",
    "                if count<=100:\n",
    "                    return 2\n",
    "                else:\n",
    "                    return 3 \n",
    "                \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.df[\"class\"] = self.df[\"retweet_count\"].apply(Classification.label)\n",
    "         \n",
    "                \n",
    "    def classify(self,features):\n",
    "        \n",
    "        x = self.df[features]\n",
    "\n",
    "        Y = self.df[[\"class\"]]\n",
    "\n",
    "        X = x.values\n",
    "\n",
    "        y = Y.values\n",
    "\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "        sc_class = StandardScaler()\n",
    "        X_train = sc_class.fit_transform(X)\n",
    "        #X_test = sc_class.transform(X_test)\n",
    "        \n",
    "        self.scaler = sc_class\n",
    "        \n",
    "        #some classifier\n",
    "        rf = RandomForestClassifier(n_estimators = 100, random_state = 0, criterion = \"entropy\")\n",
    "        \n",
    "        rf.fit(X, y)\n",
    "        \n",
    "        self.classifier = rf\n",
    "        \n",
    "        pass\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression():\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def regression_per_class(self, features):\n",
    "    #returns a regressor for every class\n",
    "        regressors=[]\n",
    "        scalers=[]\n",
    "        by_class = self.df.groupby([\"class\"])\n",
    "        for _,group in by_class:\n",
    "            X_r = group[features]\n",
    "            Y_r = group[['retweet_count']]\n",
    "            y_r = Y_r.values\n",
    "\n",
    "            #X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_r, Y_r, test_size=0.2, random_state=0)\n",
    "            sc = StandardScaler()\n",
    "            X_train_r = sc.fit_transform(X_r)\n",
    "            #X_test_r = sc.transform(X_test_r)\n",
    "            \n",
    "\n",
    "            svr = LinearSVR()\n",
    "            svr.fit(X_train_r, y_r)\n",
    "            regressors += [svr]\n",
    "            scalers+=[sc]\n",
    "            \n",
    "        self.regressors = regressors\n",
    "        self.scalers = scalers\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FE = FeatureExtraction(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instead of transforming the data (takes a lot of time), we import the already-calculated features (for details check the FeatureExtraction class).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(\"data/features_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier = Classification(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/celinehajjar/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "Classifier.classify(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regressor = Regression(Classifier.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/celinehajjar/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/celinehajjar/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/celinehajjar/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/celinehajjar/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "Regressor.regression_per_class(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it together to predict on eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = pd.read_csv(\"data/evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_reg_class(test_df, classifier, regressors, features, scalers_reg, scaler_class):\n",
    "    #we suppose that test_df already has the extracted features\n",
    "    #classify then do regression\n",
    "    y_pred = pd.DataFrame(np.zeros(len(test_df)), columns = [\"pred\"])\n",
    "    \n",
    "    #classification\n",
    "    X_class = test_df[features].values\n",
    "    X_class = scaler_class.transform(X_class)\n",
    "    y_class = classifier.predict(X_class)\n",
    "    test_df[\"class\"]=y_class\n",
    "\n",
    "    #regression\n",
    "    for c in range(4):\n",
    "        if (test_df.loc[test_df[\"class\"]==c].shape[0]!=0):\n",
    "            X_ = test_df.loc[test_df[\"class\"]==c][features].values\n",
    "            X_ = scalers_reg[c].transform(X_)\n",
    "            y_ = regressors[c].predict(X_)\n",
    "            y_pred.loc[test_df[\"class\"]==c,\"pred\"]=y_\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "FE_eval = FeatureExtraction(eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Same as before, to save time we import already transformed evaluation data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FE_eval.transform()\n",
    "#eval_ = FE_eval.transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_ = pd.read_csv(\"data/trans_eval_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rc = pred_reg_class(eval_, Classifier.classifier, Regressor.regressors, features, Regressor.scalers, Classifier.scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>285334.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.435766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.218527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>86.386002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred\n",
       "count  285334.000000\n",
       "mean        0.435766\n",
       "std         1.218527\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max        86.386002"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"classif_regr_2_predictions.txt\", 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"TweetID\", \"NoRetweets\"])\n",
    "    for index, prediction in enumerate(y_pred_rc.values):\n",
    "        writer.writerow([str(eval_['id'].iloc[index]) , str(prediction[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_.to_csv(\"data/trans_eval_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
