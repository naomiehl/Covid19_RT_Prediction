{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:02:27.080662Z",
     "start_time": "2020-12-01T16:02:25.295645Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import seaborn\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from verstack.stratified_continuous_split import scsplit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:02:28.234081Z",
     "start_time": "2020-12-01T16:02:27.084186Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>urls</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1588696955143</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>68460</td>\n",
       "      <td>1101</td>\n",
       "      <td>1226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Smh I give up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1588464948124</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>309</td>\n",
       "      <td>51</td>\n",
       "      <td>202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Most of us are Human Beings, but I think you m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1588634673360</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3241</td>\n",
       "      <td>1675</td>\n",
       "      <td>2325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Old dirty tricks Trump, at it again...like we ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      timestamp  retweet_count  user_verified  user_statuses_count  \\\n",
       "0   0  1588696955143              0          False                68460   \n",
       "1   1  1588464948124              0          False                  309   \n",
       "2   2  1588634673360              0          False                 3241   \n",
       "\n",
       "   user_followers_count  user_friends_count user_mentions urls hashtags  \\\n",
       "0                  1101                1226           NaN  NaN      NaN   \n",
       "1                    51                 202           NaN  NaN      NaN   \n",
       "2                  1675                2325           NaN  NaN      NaN   \n",
       "\n",
       "                                                text  \n",
       "0                                      Smh I give up  \n",
       "1  Most of us are Human Beings, but I think you m...  \n",
       "2  Old dirty tricks Trump, at it again...like we ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:02:28.256578Z",
     "start_time": "2020-12-01T16:02:28.236273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    665777.000000\n",
       "mean        147.687398\n",
       "std        2972.051181\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           2.000000\n",
       "max      942572.000000\n",
       "Name: retweet_count, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['retweet_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:02:28.277598Z",
     "start_time": "2020-12-01T16:02:28.258269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       422803\n",
       "1        57111\n",
       "2        25737\n",
       "3        16338\n",
       "4        11695\n",
       "         ...  \n",
       "2279         1\n",
       "2468         1\n",
       "4324         1\n",
       "1765         1\n",
       "5301         1\n",
       "Name: retweet_count, Length: 6871, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['retweet_count'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:02:28.284700Z",
     "start_time": "2020-12-01T16:02:28.279061Z"
    }
   },
   "outputs": [],
   "source": [
    "class FeatureExtraction(object):\n",
    "\n",
    "    def __init__(self, train_data):\n",
    "        self.train_data = train_data\n",
    "    \n",
    "    def transform(self):\n",
    "        train_data = self.train_data\n",
    "        \n",
    "        #user verified\n",
    "        labelencoder=LabelEncoder()\n",
    "        train_data['user_verified']=labelencoder.fit_transform(train_data['user_verified'])\n",
    "        \n",
    "        #timestamp\n",
    "        train_data[\"user_hour\"] = train_data.timestamp.apply(lambda t: (datetime.fromtimestamp(t//1000-5*3600)).hour)\n",
    "        train_data[\"user_day\"] = train_data.timestamp.apply(lambda t: (datetime.fromtimestamp(t//1000-5*3600)).weekday())\n",
    "        train_data[\"user_month\"] = train_data.timestamp.apply(lambda t: (datetime.fromtimestamp(t//1000-5*3600)).month)\n",
    "        \n",
    "        #number of hashtags\n",
    "        train_data['totalhashtag'] = train_data['hashtags'].str.split().str.len()\n",
    "        train_data['totalhashtag'] = train_data['totalhashtag'].fillna(0)\n",
    "        train_data = train_data.drop(columns=['hashtags'])\n",
    "        \n",
    "\n",
    "        #number of mentions\n",
    "        train_data['totalmentions'] = train_data['user_mentions'].str.split().str.len()\n",
    "        train_data['totalmentions'] = train_data['totalmentions'].fillna(0)\n",
    "        \n",
    "        train_data = train_data.drop(columns=['user_mentions'])\n",
    "        \n",
    "        \n",
    "        # urls\n",
    "        train_data['urls'] = train_data['urls'].fillna(0)\n",
    "        train_data = train_data.assign(urls=(train_data['urls'] !=0 ).astype(int))\n",
    "        \n",
    "      \n",
    "        self.transformed_data = train_data\n",
    "                                     \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:03:10.750434Z",
     "start_time": "2020-12-01T16:02:28.285969Z"
    }
   },
   "outputs": [],
   "source": [
    "y = train_data.retweet_count \n",
    "for i in range(train_data.shape[0]):\n",
    "       if y[i] == 0:\n",
    "            y[i] = 0\n",
    "       elif y[i]>0 and y[i]<10:\n",
    "            y[i] = 1\n",
    "       elif y[i]>10 and y[i]<100:\n",
    "            y[i] = 2\n",
    "       elif y[i]>100 and y[i]<1000:\n",
    "            y[i] = 3\n",
    "       else:\n",
    "            y[i] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:03:13.106905Z",
     "start_time": "2020-12-01T16:03:10.752096Z"
    }
   },
   "outputs": [],
   "source": [
    "FE = FeatureExtraction(train_data)\n",
    "FE.transform()\n",
    "features = FE.transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:03:13.772862Z",
     "start_time": "2020-12-01T16:03:13.108512Z"
    }
   },
   "outputs": [],
   "source": [
    "X = features[[\"user_verified\", \"user_statuses_count\", \"user_followers_count\", \"user_friends_count\",\"totalhashtag\", \"totalmentions\",\"urls\",\"user_hour\",\"user_day\",\"user_month\"]]\n",
    "X_train, X_test, y_train, y_test = scsplit(X, y, stratify=y, train_size=0.7,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:03:29.641139Z",
     "start_time": "2020-12-01T16:03:13.775014Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_model = LogisticRegression()\n",
    "train_data_model.fit(X_train,y_train)\n",
    "y_pred=train_data_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:03:29.654160Z",
     "start_time": "2020-12-01T16:03:29.647411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4310883475021779"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:03:29.672269Z",
     "start_time": "2020-12-01T16:03:29.658674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6822724223216878"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = accuracy_score(y_test,y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:03:29.702511Z",
     "start_time": "2020-12-01T16:03:29.674214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    665777.000000\n",
       "mean          0.598619\n",
       "std           0.956913\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           1.000000\n",
       "max           4.000000\n",
       "Name: retweet_count, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:03:31.692635Z",
     "start_time": "2020-12-01T16:03:29.704767Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_data = pd.read_csv(\"data/evaluation.csv\")\n",
    "FE_eval = FeatureExtraction(eval_data)\n",
    "FE_eval.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:03:31.757546Z",
     "start_time": "2020-12-01T16:03:31.694223Z"
    }
   },
   "outputs": [],
   "source": [
    "trans_eval_data = FE_eval.transformed_data\n",
    "X_eval = trans_eval_data.drop(\"text\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:03:31.905304Z",
     "start_time": "2020-12-01T16:03:31.759110Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_eval = sc.fit_transform(X_eval.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:03:32.188432Z",
     "start_time": "2020-12-01T16:03:31.907523Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 12 features per sample; expecting 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-052560c80157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_eval_pred_logistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[1;32m    287\u001b[0m                              % (X.shape[1], n_features))\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 12 features per sample; expecting 10"
     ]
    }
   ],
   "source": [
    "y_eval_pred_logistic = train_data_model.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T16:03:32.198881Z",
     "start_time": "2020-12-01T16:02:26.075Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"logistic_regression.txt\", 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"TweetID\", \"NoRetweets\"])\n",
    "    for index, prediction in enumerate(y_eval_pred_logistic):\n",
    "        writer.writerow([str(trans_eval_data['id'].iloc[index]) , str(int(prediction))])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
